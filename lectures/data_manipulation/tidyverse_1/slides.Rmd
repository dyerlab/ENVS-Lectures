---
title: "The Title"
subtitle: "The Subtitle"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "envs543-styles.css", "fonts.css"]
    seal: false
    nature:
      titleSlideClass: ["center","middle"]
      highlightStyle: default
      highlightLines: true
      ratio: "16:9"
      countIncrementalSlides: false
---
class: left, middle, inverse
background-image: url("https://live.staticflickr.com/65535/50362989122_a8ee154fea_k_d.jpg")
background-size: cover


```{r setup, include=FALSE}
knitr::opts_chunk$set( fig.retina = 3, 
                       warning = FALSE, 
                       message = FALSE)
library( knitr )
options(knitr.table.format = "html")
library( tidyverse )
library( fontawesome )
library(DiagrammeR)
library( emo )
```



# .orange[The Workflow of <br>Data Analysis]



### Environmental Data Literacy





---
class: sectionTitle

# .green[Actions]

## The *verbs* of data analysis



---
background-image: url("https://live.staticflickr.com/65535/50362129663_0d640ad239_k_d.jpg")
background-size: cover

# Data Operators

.pull-left[
There are a finite number of actions (verbs) that we can use on the raw data we work with.  

They can be combined to yield meaninful (or quimsical) inferences from our data:

&nbsp; 

.redinline[ &nbsp; Is there more sun on Fridays than on the weekend?]

&nbsp; 

.orangeinline[ &nbsp; What is the distribution of high-tide depths for each <br>&nbsp; day in January?]

&nbsp; 

.blueinline[ &nbsp; Is there a visible relationship between water salinity &<br>&nbsp;  measured pH?]


]



---
background-image: url("https://live.staticflickr.com/65535/50362827791_a32934b310_k_d.jpg")
background-size: cover

# Select

.pull-left[
Identify only subset of data columns that you are interested in using.]


---
background-image: url("https://live.staticflickr.com/65535/50362989322_6aa00c8398_k_d.jpg")
background-size: cover

# Filter

.pull-left[
Use only some subset of rows in the data based upon qualities wihtin the columns themselves.
]


---
background-image: url("https://live.staticflickr.com/65535/50362827946_d8d5508dfd_k_d.jpg")
background-size: cover

# Mutate

.pull-left[
Convert one data type to another, scaling, combining, or making any other derivative component.
]


---
background-image: url("https://live.staticflickr.com/65535/50362129893_61851436c8_k_d.jpg")
background-size: cover

# Arrange


.pull-left[
Reorder the data using values in one or more collumns to sort.
]


---
background-image: url("https://live.staticflickr.com/65535/50362869456_c869b2a0a9_k_d.jpg")
background-size: cover

# Group


.pull-left[
Partition the data set into groups based upon some taxonomy of categorization.
]


---
background-image: url("https://live.staticflickr.com/65535/50362989492_d4e281b741_k_d.jpg")
background-size: cover

# Summarize

.pull-left[

Perform operations on the data to characterize trends in the raw data as summary statistics.

]






---

# Combinations Yield Inference

Combining these actions together is how we perform the analyses.



```{r echo=FALSE, out.width='75%', out.height='30%', fig.align='center'}
graph <-
  create_graph() %>%
  add_path(
    n = 5,
    type = "step",
    label = c(
      "Load\\nData",
      "Select\\nColumns",
      "Overlay\\nPoints",
      "Overlay\\nTrend",
      "Show Plot"
    ),
    node_aes = node_aes(
      shape = c("square", "circle", "circle", "circle", "rectangle"),
      width = c(0.75, 0.75, 0.75, 0.75, 0.75),
      color = "#3C3C3C",
      fontcolor = "black",
      fillcolor = c("#61acf0", "#f0a561", "#f0a561", "#f0a561", "#cbd20a"),
      fontname = "Lato"
    ),
    edge_aes = edge_aes(# set edge aesthetics
      color = "#3C3C3C")
  ) %>%
  add_global_graph_attrs(attr = "layout",
                         value = "dot",
                         attr_type = "graph") %>%
  add_global_graph_attrs(attr = "rankdir",
                         value = "LR",
                         attr_type = "graph")

# View the graph in the Viewer
graph %>% render_graph()
```

--

```{r echo=FALSE, out.width='100%', out.height='20%', fig.align='center'}
summary <- create_graph() %>%
  add_path(
    n = 6,
    type = "step",
    label = c(
      "Load\\nData",
      "Group\\nSpecies",
      "Select\\nColumn",
      "Estimate\\nMean",
      "Estimate\\nVariance",
      "Make Table"
    ),
    node_aes = node_aes(
      shape = c("square", "circle", "circle", "circle", "circle", "rectangle"),
      width = c(0.75, 0.75, 0.75, 0.75, 0.75, 1.0),
      color = "#3C3C3C",
      fontcolor = "black",
      fillcolor = c("#61acf0", "#f0a561", "#f0a561", "#f0a561", "#f0a561", "#cbd20a"),
      fontname = "Lato"
    ),
    edge_aes = edge_aes(# set edge aesthetics
      color = "#3C3C3C")
  ) %>%
  add_global_graph_attrs(attr = "layout",
                         value = "dot",
                         attr_type = "graph") %>%
  add_global_graph_attrs(attr = "rankdir",
                         value = "LR",
                         attr_type = "graph")

# View the graph in the Viewer
summary %>% render_graph()
```






---

# The Data

The data we will be working with consist of data from the [Rice Rivers Center](https://ricerivers.vcu.edu) which contains water and atmospheric measurements from a stream of sensors in both the James River and on the bluff overlooking the river.

```{r}
library( readr )
url <- "https://docs.google.com/spreadsheets/d/1Mk1YGH9LqjF7drJE-td1G_JkdADOU0eMlrP01WFBT8s/pub?gid=0&single=true&output=csv"
rice <- read_csv( url )
names( rice )
```



---
class: sectionTitle

# .green[Selecting]

## Grabbing *only* the variables you need


---

# Column Selection

Using the column numbers instead of names.

```{r}
df <- rice[ c(1,3,5,13)]
summary( df )
```


---

# Readability & Code Maintenance

.pull-left[
- Column names are probably better than column numbers

- Additional assistance from RStudio via *pop-ups*.

- Longer term readability (like next Tuesday & Beyond!)
]

.pull-right[![Figure 1: Popup help for column names in `RStudio` for a data frame in memory](https://live.staticflickr.com/65535/50359964467_03232a3716_w_d.jpg)]




---
class: sectionTitle

# .green[Filtering]

## Extract only the records (rows) needed


---

# Row Indices

If you have some indication of which set of data you are interested in looking at, you can use the raw numerical values for the rows and extract subsets.

.left-column[

Values for 1/1/2014

```{r eval=FALSE}
df1 <- df[ 1:96, ]
head( df1 )
```
]

.right-column[
```{r echo=FALSE}
df1 <- df[ 1:96, ]
head( df1 )
```
]

--

.red[Requires us to have very intimate knowledge of how many records constitute a day and that **every** day is the same.]


---

# Logical Indices

We can use logical operators to create `TRUE/FALSE` values to select rows of interest.

.pull-left[

&nbsp;

Operator | Definition 
:-------:|------------------------
`!=`     | Not equal to
`==`     | Equal to
`>`      | Strictly greater than
`>=`     | Greater than OR equal to
`<`      | Strictly less than
`<=`     | Less than or equal to.
]

--

.pull-right[
]


---

# Logical Indices

We can use logical operators to create `TRUE/FALSE` (and `NA`) values as a vector.

```{r}
idx <- df$PAR > 0
idx[1:200]
```




---

# Logical Indices

Then use them to serve as indices on the original data.  Only the `TRUE` values will be returned.

```{r}
df1 <- df[ idx, ]
summary( df1 )
```


---

# Function Indices

We can also use various functions that return `TRUE/FALSE` values.

```{r}
df[ is.na(df$PH), ]
```



---

# Mathematical Operaions

The *modulo* operator returns the remainder after simple division (e.g., 10 modulo 3 = 1).  It can be used to grab 'every x<sup>th</sup>' element.  Here is an example of every other value (the even ones).

```{r}
(1:20 %% 2 ) == 0 
```

--

Or every third

```{r}
(1:20 %% 3 ) == 0 
```


---

# Random Samples

There is often times that we will want to go grab a random subset of data (often when looking to see you have enough sample size).  We can use the `sample()` function.

--

Grab 10 random records from `df`.


.pull-left[
```{r}
idx <- sample( 1:nrow(df), size=10, replace=FALSE )
idx
```
]

--

.pull-right[
```{r}
df[idx,]
```
]



---

# Combinations of Indices

Multiple criteria.  "Wind from particular direction *and* not night."

```{r}
par <- df$PAR > 0
wind <- df$WindDir < 30
cbind( par, wind )[30:35,]
```


---

# Logical Operators AND & OR


.pull-left[

`&`-operator must all be `TRUE`

Condition      |  Result
----------------|----------
`FALSE & FALSE` | `FALSE`
`FALSE & TRUE` | `FALSE`
`TRUE & FALSE` | `FALSE`
`TRUE & TRUE` | `TRUE`


```{r}
cbind( par, wind, AND = par & wind )[30:35,]
```
]

--


.pull-right[

`|`-operator must have at least one `TRUE`

Condition      |  Result
----------------|----------
`FALSE & FALSE` | `FALSE`
`FALSE & TRUE` | `TRUE`
`TRUE & FALSE` | `TRUE`
`TRUE & TRUE` | `TRUE`



```{r}
cbind( par, wind, OR = par | wind)[30:35,]
```
]


---

# Logical Operators XOR & NOT


.pull-left[

`xor`-operator *only* one `TRUE`

Condition      |  Result
----------------|----------
`FALSE & FALSE` | `FALSE`
`FALSE & TRUE` | `TRUE`
`TRUE & FALSE` | `TRUE`
`TRUE & TRUE` | `FALSE`


```{r}
cbind( par, wind, XOR = xor(par,wind) )[30:35,]
```
]

--


.pull-right[

`!`-flips the logical result

Condition      |  Result
----------------|----------
`!FALSE` | `TRUE`
`!TRUE` | `FALSE`

```{r}
cbind( par, NOT_PAR = !par )[30:35,]
```
]





---
class: sectionTitle

# ðŸ˜± .blue[Mutation] 

## Creating derivative data components

---

# Raw Data -> Usable Data

Data is often derived from text.

- `read_csv()` must make an estimate of a column data type should be.  

- Estimates are often *least divisive*

--

Consider the `DateTime` column in the `rice` data.

```{r}
rice$DateTime[1]
```

--

```{r}
class( rice$DateTime )
```


---

# Date & Time Challenges

We must consider the following when attempting to conduct *operations* on date and time units.

1. Many different calendars.  

2. Leap days, years, seconds.

3. Time Zones (looking at you Arizona).

4. Non-consistent base units (60 seconds, 60 minutes, 24 hours, 7 days, 28/29/30/31 days, 12 months, 100 years, 10 centuries)



---

# The Unix Epoch - Time Zero!

.red[.center[.large[00:00:00 January 1, 1970]]]


Time on computers is kept as the number of seconds since the *epoch*.  It is only .blueinline[displayed] in the Gregorian, Julian, Chinese, Jewish, and other calendars.



```{r}
Sys.time()
```

--

```{r}
unclass( Sys.time() )
```


---

# Making Time `r emo::ji("clock")`

To convert something like `r rice$DateTime[1]` from `character` to a `time` object, we need to specify the layout of the elements within the string so the functions know what to operate on.


.pull-left[

- Month as 1 or 2 digits  
- Day as 1 or 2 digits  
- Year as 4 digits  
- a space to separate date from time  
- hour (not 24-hour though)  
- minutes in 2 digits  
- seconds in 2 digits  
- a space to separate time from timezone  
- timezone  
- / separating date objects  
- : separating time objects  

]

--

.pull-right[

```{r}
rice$DateTime[1]
```


Look at the help file for `?strptime` to see these and other encodings.

```{r}
library( lubridate )
format <- "%m/%d/%Y %I:%M:%S %p"
x <- parse_date_time( rice$DateTime[1], orders=format, tz="EST")
x
```


]


---

# Making Lots of time

```{r}
rice$DateTime <- parse_date_time( rice$DateTime,
                                  orders=format,
                                  tz="EST")
summary( rice$DateTime )
```


--

```{r}
rice$DateTime[8199] - rice$DateTime[1]
```


--



```{r}
txt <- paste( "Entry 5000 '", rice$DateTime[5000], "' is julian ordinal day ",yday( rice$DateTime[5000] ), sep="")
txt
```



























---

class: middle
background-image: url("images/contour.png")
background-position: right
background-size: auto

.center[

# Questions?


![Peter Sellers](images/peter_sellers.gif)
]

<p>&nbsp;</p>

.bottom[ If you have any questions for about the content presented herein, please feel free to [submit them to me](https://docs.google.com/forms/d/e/1FAIpQLScrAGM5Zl8vZTPqV8DVSnSrf_5enypyp0717jG4PZiTlVHDjQ/viewform?usp=sf_link) and I'll get back to you as soon as possible.]


